{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YemDIGJurNi5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "inputs = torch.randn(1000,3)\n",
        "values = [[5,10,15],[20,25,30]]\n",
        "weights = torch.tensor(values)\n",
        "weights = weights.float()\n",
        "bias = torch.tensor([60,90])\n",
        "bias = bias.float()\n",
        "bias"
      ],
      "metadata": {
        "id": "WsWCVNIypvIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = inputs @ weights.t() + bias\n",
        "targets[:10], inputs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9NIjDEqrAdx",
        "outputId": "1e187db0-a5a4-4fe2-9cb0-7088ef5a723b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 98.0182, 192.7419],\n",
              "         [ 37.7384,  27.8137],\n",
              "         [ 32.4560,  26.4579],\n",
              "         [ 43.2647,  71.0543],\n",
              "         [ 39.2337,  38.3915],\n",
              "         [ 77.8414, 141.5189],\n",
              "         [ 50.5369,  68.2979],\n",
              "         [ 98.6089, 182.0050],\n",
              "         [ 88.5168, 166.3071],\n",
              "         [ 64.9838, 112.1569]]),\n",
              " tensor([[ 1.9269,  1.4873,  0.9007],\n",
              "         [-2.1055,  0.6784, -1.2345],\n",
              "         [-0.0431, -1.6047, -0.7521],\n",
              "         [ 1.6487, -0.3925, -1.4036],\n",
              "         [-0.7279, -0.5594, -0.7688],\n",
              "         [ 0.7624,  1.6423, -0.1596],\n",
              "         [-0.4974,  0.4396, -0.7581],\n",
              "         [ 1.0783,  0.8008,  1.6806],\n",
              "         [ 1.2791,  1.2964,  0.6105],\n",
              "         [ 1.3347, -0.2316,  0.0418]]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(0.8 * len(inputs))\n",
        "input_train , target_train = inputs[:train_split], targets[:train_split]\n",
        "input_test, target_test = inputs[train_split:], targets[train_split:]\n"
      ],
      "metadata": {
        "id": "dYUrcZT9s_3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Visualization will happen later\n"
      ],
      "metadata": {
        "id": "Kzc1C96G1IUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(size=(2,3), dtype=torch.float), requires_grad=True)\n",
        "    self.bias = nn.Parameter(torch.randn(2, dtype=torch.float), requires_grad=True)\n",
        "  def forward(self, x):\n",
        "    return x @ self.weights.t() + self.bias\n"
      ],
      "metadata": {
        "id": "OvJqmmRt1Q1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed since nn.Parameters are randomly generated\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create an instance of the model\n",
        "model_2 = LinearRegressionModel()\n",
        "\n",
        "# check the nn.parameters that we created randomly\n",
        "list(model_2.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyGzaRJViG__",
        "outputId": "36088022-1450-402a-a9d4-25d2e8e65d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.3367,  0.1288,  0.2345],\n",
              "         [ 0.2303, -1.1229, -0.1863]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 2.2082, -0.6380], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list named parameters\n",
        "model_2.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R_MedxojRhw",
        "outputId": "c9fefa76-c80b-49ed-99d4-39bd70716448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights',\n",
              "              tensor([[ 0.3367,  0.1288,  0.2345],\n",
              "                      [ 0.2303, -1.1229, -0.1863]])),\n",
              "             ('bias', tensor([ 2.2082, -0.6380]))])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions with the model\n",
        "with torch.inference_mode():\n",
        "  target_preds = model_2(input_test)"
      ],
      "metadata": {
        "id": "sD_PVsBPjtA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check on the target_test values"
      ],
      "metadata": {
        "id": "MlhcbrCJkdv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the predictions\n",
        "print(f\"Number of testing samples :{len(target_test)}\")\n",
        "print(f\"Number of predictions made: {len(target_preds)}\")\n",
        "print(f\"Predicted values: \\n {target_preds}\")"
      ],
      "metadata": {
        "id": "iBWAzGEglC_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot predictions"
      ],
      "metadata": {
        "id": "XRjZnlPomJ7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(model_2.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVoK7_NimMxH",
        "outputId": "38d73f26-fa1d-45bf-a5e9-46d692387092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.3367,  0.1288,  0.2345],\n",
              "         [ 0.2303, -1.1229, -0.1863]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 2.2082, -0.6380], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.L1Loss() # MAE is the same as L1Loss\n",
        "\n",
        "# create an optimizer\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "Yj6_Tn_InLhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# set the number of epochs (How many times the model will pass the training data)\n",
        "epochs = 100000\n",
        "\n",
        "# create empty loss lists to track values\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  ### Training\n",
        "\n",
        "  # put model in training mode\n",
        "  model_2.train()\n",
        "\n",
        "  # forward pass on the training data using the forward function\n",
        "  target_preds = model_2(input_train)\n",
        "\n",
        "  # calculate the loss\n",
        "  loss = loss_fn(target_preds, target_train)\n",
        "\n",
        "  # Zerograd of the optimizer\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Loss Backwards\n",
        "  loss.backward()\n",
        "\n",
        "  # progress the optimizer\n",
        "  optimizer.step()\n",
        "\n",
        "  ## Testing\n",
        "\n",
        "  # put the model in evaluation mode\n",
        "  model_2.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    #1 forward pass on the test data\n",
        "    test_preds = model_2(input_test)\n",
        "\n",
        "    #2 Calculate the loss on test data\n",
        "    test_loss = loss_fn(test_preds, target_test.type(torch.float))  # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
        "\n",
        "    # print out what's happening\n",
        "    if epoch % 1000== 0:\n",
        "      epoch_count.append(epoch)\n",
        "      train_loss_values.append(loss.detach().numpy())\n",
        "      test_loss_values.append(test_loss.detach().numpy())\n",
        "      print(f\"Epoch: {epoch} | MAE Train Loss : {loss} | MAE Test Loss: {test_loss}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZEcggM3oP20",
        "outputId": "203e8407-eff9-45f6-e223-e350fa9b74b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | MAE Train Loss : 30.067737579345703 | MAE Test Loss: 30.195606231689453\n",
            "Epoch: 1000 | MAE Train Loss : 26.3846378326416 | MAE Test Loss: 26.482925415039062\n",
            "Epoch: 2000 | MAE Train Loss : 22.79364585876465 | MAE Test Loss: 22.852783203125\n",
            "Epoch: 3000 | MAE Train Loss : 19.281875610351562 | MAE Test Loss: 19.29962921142578\n",
            "Epoch: 4000 | MAE Train Loss : 16.4222469329834 | MAE Test Loss: 16.435205459594727\n",
            "Epoch: 5000 | MAE Train Loss : 14.614543914794922 | MAE Test Loss: 14.62436294555664\n",
            "Epoch: 6000 | MAE Train Loss : 12.81957721710205 | MAE Test Loss: 12.830827713012695\n",
            "Epoch: 7000 | MAE Train Loss : 11.040485382080078 | MAE Test Loss: 11.056778907775879\n",
            "Epoch: 8000 | MAE Train Loss : 9.287463188171387 | MAE Test Loss: 9.310379981994629\n",
            "Epoch: 9000 | MAE Train Loss : 7.5503644943237305 | MAE Test Loss: 7.587217807769775\n",
            "Epoch: 10000 | MAE Train Loss : 5.841482639312744 | MAE Test Loss: 5.886124134063721\n",
            "Epoch: 11000 | MAE Train Loss : 4.155818939208984 | MAE Test Loss: 4.1981201171875\n",
            "Epoch: 12000 | MAE Train Loss : 2.494467258453369 | MAE Test Loss: 2.5226845741271973\n",
            "Epoch: 13000 | MAE Train Loss : 0.8517475724220276 | MAE Test Loss: 0.859816312789917\n",
            "Epoch: 14000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 15000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 16000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 17000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 18000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 19000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 20000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 21000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 22000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 23000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 24000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 25000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 26000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 27000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 28000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 29000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 30000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 31000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 32000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 33000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 34000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 35000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 36000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 37000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 38000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 39000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 40000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 41000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 42000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 43000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 44000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 45000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 46000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 47000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 48000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 49000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 50000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 51000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 52000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 53000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 54000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 55000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 56000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 57000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 58000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 59000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 60000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 61000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 62000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 63000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 64000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 65000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 66000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 67000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 68000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 69000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 70000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 71000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 72000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 73000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 74000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 75000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 76000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 77000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 78000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 79000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 80000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 81000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 82000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 83000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 84000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 85000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 86000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 87000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 88000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 89000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 90000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 91000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 92000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 93000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 94000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 95000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 96000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 97000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 98000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n",
            "Epoch: 99000 | MAE Train Loss : 0.0016117787454277277 | MAE Test Loss: 0.002594528254121542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss Curves\n"
      ],
      "metadata": {
        "id": "wuxesLmdzL_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find our Model's learned parameters\n",
        "print(\"The model learned the following values for weights and bias:\")\n",
        "print(model_2.state_dict())\n",
        "print(\"\\nAnd the original values for weights and bias are:\")\n",
        "print(f\"weights: {weights}, bias: {bias}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoBHRXlkzSC3",
        "outputId": "f4613c25-d2b3-4dea-ecf8-5f7579ebfb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model learned the following values for weights and bias:\n",
            "OrderedDict([('weights', tensor([[ 5.0000, 10.0001, 14.9999],\n",
            "        [20.0010, 25.0007, 30.0002]])), ('bias', tensor([60.0021, 90.0005]))])\n",
            "\n",
            "And the original values for weights and bias are:\n",
            "weights: tensor([[ 5., 10., 15.],\n",
            "        [20., 25., 30.]]), bias: tensor([60., 90.])\n"
          ]
        }
      ]
    }
  ]
}